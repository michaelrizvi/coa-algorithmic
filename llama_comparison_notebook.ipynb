{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation vs Communication Tradeoff Analysis: Llama-8B vs Llama-70B\n",
    "\n",
    "This notebook analyzes the computation vs communication tradeoff for Llama-8B and Llama-70B models using the same methodology as the pareto-notebook.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import scienceplots\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure plotting style for ICLR paper format with 12pt font\n",
    "plt.style.use(['science', 'ieee'])  # Enables LaTeX + clean scientific styling\n",
    "\n",
    "# LaTeX font settings - 12pt for ICLR format\n",
    "plt.rcParams.update({\n",
    "    'text.usetex': True,\n",
    "    'font.family': 'serif',\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 13,\n",
    "    'axes.labelsize': 12,\n",
    "    'legend.fontsize': 11,\n",
    "    'xtick.labelsize': 11,\n",
    "    'ytick.labelsize': 11\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file containing llama-8B and llama-70B data\n",
    "df = pd.read_csv('data/avg_completion_tokens_llama8B_70B.csv')\n",
    "\n",
    "# Display basic information about the data\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions from the original pareto notebook\n",
    "def compute_num_agents(sequence_length, branching_factor):\n",
    "    \"\"\"\n",
    "    Compute total number of agents in PrefixSumAgents hierarchical structure.\n",
    "    \n",
    "    Args:\n",
    "        sequence_length: Length of input sequence (e.g., 32, 64, 128)\n",
    "        branching_factor: Branching factor b (number of inputs each manager processes)\n",
    "    \n",
    "    Returns:\n",
    "        int: Total number of manager agents needed\n",
    "    \"\"\"\n",
    "    if branching_factor <= 1:\n",
    "        return sequence_length  # Each element needs its own agent\n",
    "    \n",
    "    return math.ceil((sequence_length - 1) / (branching_factor - 1))\n",
    "\n",
    "def compute_total_communication(sequence_length, branching_factor):\n",
    "    \"\"\"\n",
    "    Compute total communication (number of edges) in PrefixSumAgents b-ary tree.\n",
    "    \n",
    "    Args:\n",
    "        sequence_length: Length of input sequence (e.g., 32, 64, 128)  \n",
    "        branching_factor: Branching factor b (number of inputs each manager processes)\n",
    "    \n",
    "    Returns:\n",
    "        int: Total number of edges (communications) in the tree\n",
    "    \"\"\"\n",
    "    if branching_factor <= 1:\n",
    "        return sequence_length - 1  # Linear chain\n",
    "    \n",
    "    total_edges = 0\n",
    "    current_level_size = sequence_length\n",
    "    \n",
    "    # Simulate the hierarchical processing\n",
    "    while current_level_size > 1:\n",
    "        # Number of managers at next level\n",
    "        next_level_size = math.ceil(current_level_size / branching_factor)\n",
    "        \n",
    "        # Each manager receives up to b inputs, but we need to count actual edges\n",
    "        # The number of edges from current level to next level equals current_level_size\n",
    "        total_edges += current_level_size\n",
    "        \n",
    "        current_level_size = next_level_size\n",
    "    \n",
    "    return total_edges\n",
    "\n",
    "def extract_sequence_info(column_name):\n",
    "    \"\"\"Extract sequence length from column name.\"\"\"\n",
    "    # Example: 'pareto_prefixsum_seq128_b1-6_llama70B - avg_completion_tokens'\n",
    "    seq_match = re.search(r'seq(\\d+)', column_name)\n",
    "    sequence_length = int(seq_match.group(1)) if seq_match else None\n",
    "    return sequence_length\n",
    "\n",
    "def extract_model_info(column_name):\n",
    "    \"\"\"Extract model type (8B or 70B) from column name.\"\"\"\n",
    "    if 'llama8B' in column_name:\n",
    "        return '8B'\n",
    "    elif 'llama70B' in column_name:\n",
    "        return '70B'\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out MIN/MAX columns and step columns, keeping only the main metrics\n",
    "def filter_columns(df):\n",
    "    return df[[col for col in df.columns if all(x not in col for x in ['MIN', 'MAX', '_step'])]]\n",
    "\n",
    "df_filtered = filter_columns(df)\n",
    "print(\"Filtered columns:\")\n",
    "print(df_filtered.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_computation_vs_communication(model_type='8B', title_suffix=''):\n",
    "    \"\"\"\n",
    "    Plot Total Computation (tokens) vs Total Communication (edges) for specified model.\n",
    "    Updated to remove accuracy shading and change y-axis to Computation Depth.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(5.5, 3.2))  # Wider to accommodate legend on the right\n",
    "    \n",
    "    # Extract columns for the specified model type\n",
    "    model_cols = [col for col in df_filtered.columns \n",
    "                  if col != 'branching_factor' and f'llama{model_type}' in col]\n",
    "    \n",
    "    # Extract unique sequence lengths for this model, filtering to keep only N>=64\n",
    "    seq_lengths = set()\n",
    "    for col in model_cols:\n",
    "        seq_len = extract_sequence_info(col)\n",
    "        if seq_len and seq_len >= 64:  # Filter to keep only N>=64\n",
    "            seq_lengths.add(seq_len)\n",
    "    \n",
    "    seq_lengths = sorted(seq_lengths)\n",
    "    # Enhanced colors for better print quality and accessibility\n",
    "    colors = ['#2E5EAA', '#2E8B57', '#B22222', '#FF8C00']\n",
    "    \n",
    "    # Create a subplot with space for legend on the right\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    for i, seq_len in enumerate(seq_lengths):\n",
    "        # Find the column for this sequence length and model\n",
    "        token_col = None\n",
    "        for col in model_cols:\n",
    "            if f'seq{seq_len}' in col:\n",
    "                token_col = col\n",
    "                break\n",
    "        \n",
    "        if token_col:\n",
    "            # Filter out NaN values\n",
    "            valid_mask = ~pd.isna(df_filtered[token_col])\n",
    "            valid_data = df_filtered[valid_mask]\n",
    "            \n",
    "            if len(valid_data) > 0:\n",
    "                # Compute total communication (edges)\n",
    "                total_communications = valid_data['branching_factor'].apply(\n",
    "                    lambda b: compute_total_communication(seq_len, b)\n",
    "                )\n",
    "                \n",
    "                # Use completion tokens as total computation\n",
    "                total_computation = valid_data[token_col]\n",
    "                \n",
    "                # Get the base color for this sequence length\n",
    "                base_color = colors[i % len(colors)]\n",
    "                \n",
    "                # Plot the connecting line\n",
    "                plt.plot(total_communications, total_computation, \n",
    "                        linewidth=1.5,\n",
    "                        color=base_color,\n",
    "                        linestyle='-',\n",
    "                        alpha=0.8,\n",
    "                        label=f'$N={seq_len}$',\n",
    "                        zorder=3)\n",
    "                \n",
    "                # Plot points without accuracy-based shading\n",
    "                plt.scatter(total_communications, total_computation,\n",
    "                          color=base_color,\n",
    "                          alpha=0.8,\n",
    "                          s=60,\n",
    "                          edgecolors='white',\n",
    "                          linewidth=0.5,\n",
    "                          zorder=5)\n",
    "    \n",
    "    plt.xlabel(r'\\textbf{Total Communication (Edges)}')\n",
    "    plt.ylabel(r'\\textbf{Computation Depth}')\n",
    "    plt.title(r'\\textbf{' + f'Llama-{model_type}: Computation vs Communication' + '}', pad=15)\n",
    "    \n",
    "    # Enhanced legend with sequence lengths\n",
    "    legend1 = plt.legend(frameon=True, loc='upper left', fontsize=9, \n",
    "                        fancybox=True, shadow=True, framealpha=0.95,\n",
    "                        edgecolor='black', facecolor='white')\n",
    "    legend1.get_frame().set_linewidth(0.8)\n",
    "    \n",
    "    # Better grid styling\n",
    "    plt.grid(True, linestyle='--', linewidth=0.6, alpha=0.6, color='gray')\n",
    "    \n",
    "    # Clean up spines for professional look\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(0.8)\n",
    "    ax.spines['bottom'].set_linewidth(0.8)\n",
    "    \n",
    "    # Better tick formatting\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True, nbins=6))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(nbins=6))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # High-quality output for publication\n",
    "    filename = f\"figures/computation_vs_communication_llama{model_type.lower()}.pdf\"\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=300, facecolor='white')\n",
    "    print(f\"Saved plot as {filename}\")\n",
    "    plt.show()\n",
    "\n",
    "# Create plots for both models\n",
    "plot_computation_vs_communication('8B')\n",
    "plot_computation_vs_communication('70B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some example calculations for verification (N>=64 only)\n",
    "print(\"Example calculations for verification:\")\n",
    "print(\"\\nLlama-8B data:\")\n",
    "print(\"Seq Length | Branching Factor | Total Communication | Avg Completion Tokens\")\n",
    "print(\"-----------|------------------|--------------------|-----------------------\")\n",
    "\n",
    "# Find columns for 8B model\n",
    "model_8b_cols = [col for col in df_filtered.columns if 'llama8B' in col]\n",
    "\n",
    "for col in model_8b_cols:\n",
    "    seq_len = extract_sequence_info(col)\n",
    "    if seq_len and seq_len >= 64:  # Filter to keep only N>=64\n",
    "        for _, row in df_filtered.iterrows():\n",
    "            if pd.notna(row[col]):\n",
    "                b = row['branching_factor']\n",
    "                comm = compute_total_communication(seq_len, b)\n",
    "                tokens = row[col]\n",
    "                print(f\"    {seq_len:3d}    |        {b:2d}        |        {comm:4d}        |       {tokens:.1f}\")\n",
    "        print()\n",
    "\n",
    "print(\"\\nLlama-70B data:\")\n",
    "print(\"Seq Length | Branching Factor | Total Communication | Avg Completion Tokens\")\n",
    "print(\"-----------|------------------|--------------------|-----------------------\")\n",
    "\n",
    "# Find columns for 70B model\n",
    "model_70b_cols = [col for col in df_filtered.columns if 'llama70B' in col]\n",
    "\n",
    "for col in model_70b_cols:\n",
    "    seq_len = extract_sequence_info(col)\n",
    "    if seq_len and seq_len >= 64:  # Filter to keep only N>=64\n",
    "        for _, row in df_filtered.iterrows():\n",
    "            if pd.notna(row[col]):\n",
    "                b = row['branching_factor']\n",
    "                comm = compute_total_communication(seq_len, b)\n",
    "                tokens = row[col]\n",
    "                print(f\"    {seq_len:3d}    |        {b:2d}        |        {comm:4d}        |       {tokens:.1f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis: Compare models side by side for same sequence length\n",
    "def plot_model_comparison(seq_length=128):\n",
    "    \"\"\"\n",
    "    Plot comparison between 8B and 70B models for a specific sequence length.\n",
    "    Updated to remove accuracy shading and change y-axis to Computation Depth.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(5.5, 3.2))  # Wider to accommodate legend on the right\n",
    "    \n",
    "    colors = ['#2E5EAA', '#B22222']  # Enhanced colors for better contrast\n",
    "    models = ['8B', '70B']\n",
    "    \n",
    "    for i, model_type in enumerate(models):\n",
    "        # Find the column for this model and sequence length\n",
    "        token_col = None\n",
    "        for col in df_filtered.columns:\n",
    "            if f'seq{seq_length}' in col and f'llama{model_type}' in col:\n",
    "                token_col = col\n",
    "                break\n",
    "        \n",
    "        if token_col:\n",
    "            # Filter out NaN values\n",
    "            valid_mask = ~pd.isna(df_filtered[token_col])\n",
    "            valid_data = df_filtered[valid_mask]\n",
    "            \n",
    "            if len(valid_data) > 0:\n",
    "                # Compute total communication (edges)\n",
    "                total_communications = valid_data['branching_factor'].apply(\n",
    "                    lambda b: compute_total_communication(seq_length, b)\n",
    "                )\n",
    "                \n",
    "                # Use completion tokens as total computation\n",
    "                total_computation = valid_data[token_col]\n",
    "                \n",
    "                # Get the base color for this model\n",
    "                base_color = colors[i]\n",
    "                \n",
    "                # Plot the connecting line first\n",
    "                plt.plot(total_communications, total_computation, \n",
    "                        linewidth=2.0, \n",
    "                        color=base_color,\n",
    "                        linestyle='-',\n",
    "                        alpha=0.8,\n",
    "                        label=f'Llama-{model_type}',\n",
    "                        zorder=3)\n",
    "                \n",
    "                # Plot points without accuracy-based shading\n",
    "                plt.scatter(total_communications, total_computation,\n",
    "                          color=base_color,\n",
    "                          alpha=0.8,\n",
    "                          s=80,\n",
    "                          edgecolors='white',\n",
    "                          linewidth=1.0,\n",
    "                          zorder=5)\n",
    "    \n",
    "    plt.xlabel(r'\\textbf{Total Communication (Edges)}')\n",
    "    plt.ylabel(r'\\textbf{Computation Depth}')\n",
    "    plt.title(r'\\textbf{' + f'Model Comparison (N={seq_length})' + '}', pad=15)\n",
    "    \n",
    "    # Enhanced legend\n",
    "    legend = plt.legend(frameon=True, loc='upper left', fontsize=10,\n",
    "                       fancybox=True, shadow=True, framealpha=0.95,\n",
    "                       edgecolor='black', facecolor='white')\n",
    "    legend.get_frame().set_linewidth(0.8)\n",
    "    \n",
    "    plt.grid(True, linestyle='--', linewidth=0.6, alpha=0.6, color='gray')\n",
    "    \n",
    "    # Clean up spines\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(0.8)\n",
    "    ax.spines['bottom'].set_linewidth(0.8)\n",
    "    \n",
    "    # Better tick formatting\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True, nbins=6))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(nbins=6))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # High-quality output\n",
    "    filename = f\"figures/model_comparison_seq{seq_length}.pdf\"\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=300, facecolor='white')\n",
    "    print(f\"Saved comparison plot as {filename}\")\n",
    "    plt.show()\n",
    "\n",
    "# Create comparison plots for different sequence lengths (N>=64 only)\n",
    "for seq_len in [64, 128, 256]:  # Removed 32, keeping only N>=64\n",
    "    # Check if both models have data for this sequence length\n",
    "    has_8b = any(f'seq{seq_len}' in col and 'llama8B' in col for col in df_filtered.columns)\n",
    "    has_70b = any(f'seq{seq_len}' in col and 'llama70B' in col for col in df_filtered.columns)\n",
    "    \n",
    "    if has_8b and has_70b:\n",
    "        plot_model_comparison(seq_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
