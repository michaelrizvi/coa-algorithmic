{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6393e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['science', 'no-latex'])  # Optional: replace 'no-latex' with 'ieee' if using LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cdb187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframe from csv named 'parity_data.csv'\n",
    "df = pd.read_csv('parity_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82785bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()  # Display the first few rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33086ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the column names of df\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb7470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[col for col in df.columns if 'MIN' not in col and 'MAX' not in col and 'step' not in col]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f560c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use(['science', 'ieee'])  # Enables LaTeX + clean scientific styling\n",
    "\n",
    "# LaTeX font settings\n",
    "plt.rcParams.update({\n",
    "    'text.usetex': True,\n",
    "    'font.family': 'serif',\n",
    "    'font.size': 8,\n",
    "    'axes.titlesize': 9,\n",
    "    'axes.labelsize': 8,\n",
    "    'legend.fontsize': 7,\n",
    "    'xtick.labelsize': 7,\n",
    "    'ytick.labelsize': 7\n",
    "})\n",
    "\n",
    "# Filter columns\n",
    "filtered_df = df[[col for col in df.columns if all(x not in col for x in ['MIN', 'MAX', 'step'])]]\n",
    "\n",
    "methods = ['prefix-sum', 'maj-voting', 'coa']\n",
    "sequence_lengths = df['sequence_length']\n",
    "best_accs = {method: [] for method in methods}\n",
    "error_bars = {method: [] for method in methods}\n",
    "\n",
    "for method in methods:\n",
    "    method_cols = [col for col in filtered_df.columns if method in col and 'avg_accuracy' in col]\n",
    "    for _, row in df.iterrows():\n",
    "        # Find best accuracy for this method at this sequence length\n",
    "        method_accs = [row[col] for col in method_cols if pd.notna(row[col])]\n",
    "        \n",
    "        if method_accs:\n",
    "            best_acc = max(method_accs)\n",
    "            best_accs[method].append(best_acc)\n",
    "            \n",
    "            # Calculate standard error: sqrt(p * (1-p) / n) where n=100 runs\n",
    "            std_error = np.sqrt(best_acc * (1 - best_acc) / 100)\n",
    "            error_bars[method].append(std_error)\n",
    "        else:\n",
    "            best_accs[method].append(0)\n",
    "            error_bars[method].append(0)\n",
    "\n",
    "# Plotting\n",
    "bar_width = 0.25\n",
    "x_pos = range(len(sequence_lengths))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.5, 2.2))  # Paper-friendly size\n",
    "colors = ['#4C72B0', '#55A868', '#C44E52']\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    ax.bar(\n",
    "        [p + i * bar_width for p in x_pos],\n",
    "        best_accs[method],\n",
    "        width=bar_width,\n",
    "        label=method.replace('-', ' ').title(),\n",
    "        color=colors[i],\n",
    "        yerr=error_bars[method],\n",
    "        capsize=2,\n",
    "        error_kw={'linewidth': 0.5, 'capthick': 0.5}\n",
    "    )\n",
    "\n",
    "ax.set_xticks([p + bar_width for p in x_pos])\n",
    "ax.set_xticklabels(sequence_lengths)\n",
    "ax.set_xlabel(r'\\textbf{Sequence Length}')\n",
    "ax.set_ylabel(r'\\textbf{Accuracy}')\n",
    "ax.legend(frameon=False, loc='upper right')\n",
    "ax.grid(True, axis='y', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"accuracy_vs_sequence_length.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n8hu0mpwbl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best hyperparameter values for each agent type and sequence length\n",
    "import re\n",
    "\n",
    "def extract_hyperparams(col_name):\n",
    "    \"\"\"Extract hyperparameters from column name\"\"\"\n",
    "    if 'maj-voting' in col_name:\n",
    "        match = re.search(r'agents(\\d+)', col_name)\n",
    "        return int(match.group(1)) if match else None\n",
    "    elif 'coa' in col_name:\n",
    "        match = re.search(r'chunk(\\d+)', col_name)\n",
    "        return int(match.group(1)) if match else None\n",
    "    elif 'prefix-sum' in col_name:\n",
    "        match = re.search(r'b(\\d+)', col_name)\n",
    "        return int(match.group(1)) if match else None\n",
    "    return None\n",
    "\n",
    "# Create results dictionary\n",
    "best_hyperparams = {\n",
    "    'maj-voting': {},\n",
    "    'coa': {},  \n",
    "    'prefix-sum': {}\n",
    "}\n",
    "\n",
    "for method in ['maj-voting', 'coa', 'prefix-sum']:\n",
    "    method_cols = [col for col in filtered_df.columns if method in col and 'avg_accuracy' in col]\n",
    "    \n",
    "    for seq_len in sequence_lengths:\n",
    "        row_data = filtered_df[filtered_df['sequence_length'] == seq_len].iloc[0]\n",
    "        \n",
    "        # Get accuracies for this method and sequence length\n",
    "        method_accs = {}\n",
    "        for col in method_cols:\n",
    "            acc = row_data[col]\n",
    "            if pd.notna(acc):  # Only include non-NaN values\n",
    "                hyperparam = extract_hyperparams(col)\n",
    "                if hyperparam is not None:\n",
    "                    method_accs[hyperparam] = acc\n",
    "        \n",
    "        # Find best hyperparameter\n",
    "        if method_accs:\n",
    "            best_hyperparam = max(method_accs.keys(), key=lambda k: method_accs[k])\n",
    "            best_hyperparams[method][seq_len] = {\n",
    "                'hyperparam': best_hyperparam,\n",
    "                'accuracy': method_accs[best_hyperparam]\n",
    "            }\n",
    "\n",
    "# Display results\n",
    "print(\"Best hyperparameters for each agent type and sequence length:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for method in ['maj-voting', 'coa', 'prefix-sum']:\n",
    "    print(f\"\\n{method.upper().replace('-', ' ')}:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if method == 'maj-voting':\n",
    "        param_name = \"num_agents\"\n",
    "    elif method == 'coa':\n",
    "        param_name = \"chunk_size\"\n",
    "    else:  # prefix-sum\n",
    "        param_name = \"branching_factor\"\n",
    "    \n",
    "    for seq_len in sorted(best_hyperparams[method].keys()):\n",
    "        result = best_hyperparams[method][seq_len]\n",
    "        print(f\"Seq length {seq_len:3d}: {param_name}={result['hyperparam']:2d}, accuracy={result['accuracy']:.3f}\")\n",
    "\n",
    "# Create a summary table\n",
    "summary_data = []\n",
    "for method in ['maj-voting', 'coa', 'prefix-sum']:\n",
    "    for seq_len in sorted(best_hyperparams[method].keys()):\n",
    "        result = best_hyperparams[method][seq_len]\n",
    "        summary_data.append({\n",
    "            'Method': method.replace('-', '_'),\n",
    "            'Sequence Length': seq_len,\n",
    "            'Best Hyperparam': result['hyperparam'],\n",
    "            'Best Accuracy': result['accuracy']\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(f\"\\n\\nSummary Table:\")\n",
    "print(\"=\" * 60)\n",
    "print(summary_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
